# -*- coding: utf-8 -*-
"""session3_assignment_GPU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d1GYWR72JBMooo5RNBc6t8YSW9jDGn1C
"""

# importing the required libraries
import torch
import torchvision
import torchvision.transforms as transforms
import numpy as np

# downloading the FashionMnist dataset

train_set = torchvision.datasets.FashionMNIST(
    root='./data'
    ,train=True
    ,download=True
    ,transform=transforms.Compose([
        transforms.ToTensor()
    ])
)

batch_size = 100
train_loader = torch.utils.data.DataLoader(train_set, batch_size=100) #DataLoader is used to create batches

# dividing the data into training and validation data
# out of 60,000 images, 59,000 are considered for training and 1000 for validation set
count  = 0
training_data = []
validation_data = []
for batch in train_loader:
  count += 1
  if(count<591):
    training_data.append(batch)
  else:
    validation_data.append(batch)

print("training set size",len(training_data)*batch_size)
print("validation set size",len(validation_data)*batch_size)

# All the convolutional layers are of 3x3 kernel size
# All the maxpool layers are of 2x2 size with stride 2

import torch.nn.functional as F
import torch.nn as nn
class Network(nn.Module):
    def __init__(self):
        super().__init__()
        
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3) # kernel_size = (1x3x3)x8, input_size = 28x28, output_size = 26x26
        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3) # kernel_size = (8x3x3)x16, input_size = 26x26, output_size = 24x24
        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)# kernel_size = (16x3x3)x32, input_size = 12x12, output_size = 10x10
        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)# kernel_size = (32x3x3)x64, input_size = 10x10, output_size = 8x8
        #self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

        self.fc1 = nn.Linear(in_features=64 * 4 * 4, out_features=64*4)
        self.fc2 = nn.Linear(in_features=64*4, out_features=64)
        self.out1 = nn.Linear(in_features=64, out_features=10) # This is for the number output from MNIST data
        self.out2 = nn.Linear(in_features=20, out_features=64) # This layer stacks the number output from MNIST data set and one hot code of random number
        self.out3 = nn.Linear(in_features=64, out_features=20) # The sum output(of size 20)

    def forward(self, t, rand_num):
       
        t = self.conv1(t)
        t = F.relu(t)
        t = self.conv2(t)
        t = F.relu(t)
        #t = t.cuda()
        t = F.max_pool2d(t, kernel_size=2, stride=2)
        #t = t.cuda()

        # (3) hidden conv layer
        t = self.conv3(t)
        t = F.relu(t)
        t = self.conv4(t)
        t = F.relu(t)
        t = F.max_pool2d(t, kernel_size=2, stride=2)

        # (4) hidden linear layer
        t = t.reshape(-1, 64 * 4 * 4) #Flattening output for FC layers
        t = self.fc1(t)
        t = F.relu(t)

        # (5) hidden linear layer
        t = self.fc2(t)
        t = F.relu(t)

        # (6) output layer
        t1 = self.out1(t)
        #print(t1)
        t2 = t1.argmax(dim=1) # The position where MNIST ouput is max is taken
        #print("1_t2.shape",t2.shape)
        t2 = F.one_hot(t2, num_classes=10) # The MNIST output is converted to one hot encoding
        #print("2_t2.shape",t2.shape)
        t_rand = F.one_hot(torch.tensor(rand_num),num_classes=10) # the random output is converted to one hot encoding
        #print("3_t_rand.shape",t_rand.shape)
        #t_rand = t_rand.unsqueeze(0)
        t_both = torch.stack((t2,t_rand),dim=1) # The MNIST output encoding and random output encoding are stacked 
        #print("4_t_both.shape",t_both.shape)
        t_both = t_both.reshape(batch_size,-1)
        #print("5_t_both.shape",t_both.shape)
        t_both = torch.tensor(t_both,dtype=torch.float32)
        #print("6_t_both.shape",t_both.shape)
        #print(t_both.shape)
        t_both = self.out2(t_both) # The stacked output is connected to FC layers
        t_both = F.relu(t_both)

        t_both = self.out3(t_both) # The final sum output of size 20
        #t_both = F.relu(t_both)

        #t = F.softmax(t)
        #t = F.softmax(t, dim=1)
        #t = t.argmax(dim=1)

        return t1,t_both #returing both MNIST detection ans sum

import torch.optim as optim
network = Network()
network = network.cuda() # The network is moved to GPU
torch.set_grad_enabled(True)
optimizer = optim.Adam(network.parameters(), lr=0.01) # Adam optimier is used
#print(optimizer.device)

# This is to give MNIST detection and sum accuracy
def get_num_correct2(pred1, pred2, labels,rand_num):
  return pred1.argmax(dim=1).eq(labels).sum().item(),pred2.argmax(dim=1).eq(labels+rand_num).sum().item()

import random
for i in range(50):
  total_correct_detect = 0
  total_correct_sum = 0
  #print("total_loss",total_loss.device)
  for batch in training_data:
    images,labels = batch
    #print("cpu_device",images.device)
    images,labels = images.cuda(),labels.cuda() # The data is moved to GPU
    #print(labels.shape)
    rand_num = []
    for j in range(batch_size):
      rand_num.append(random.randint(0,9)) # creating the rand numbers of batch size
    #print(len(rand_num))
    rand_num = torch.tensor(rand_num)
    rand_num = rand_num.cuda() # moving random number to GPU
    
    pred1,pred2 =  network(images,rand_num) # pred1 is predictions of MNIST data and pred2 is for sum 
    
    loss1 = F.cross_entropy(pred1,labels) # loss for MNIST detection
    loss2 = F.cross_entropy(pred2,labels+rand_num) # loss for sum accuracy
    
    loss = loss1 + loss2 # total loss is the sum of loss

    correct_detect, correct_sum = get_num_correct2(pred1, pred2, labels,rand_num) # getting the accuracy
    total_correct_detect += correct_detect
    total_correct_sum += correct_sum
    total_loss += loss
    #print("total_loss",total_loss.device)
    #print("loss",loss)
    optimizer.zero_grad()
    loss.backward() # Backward propagation
    optimizer.step() # Updating the gradients

  print("epoch",i+1,"loss",total_loss,"detection_accuracy :",total_correct_detect*100/(len(training_data)*batch_size),"sum_accuracy :",total_correct_sum*100/(len(training_data)*batch_size))
  #print("epoch",i+1,"loss",total_loss,"accuracy :",total_correct_sum*100/(len(training_data)*batch_size))



# the accuracy for validation data
total_val_detect_correct = 0
total_val_sum_correct = 0
#total_loss = 0
for batch in validation_data:
  images,labels = batch
  images,labels = images.cuda(),labels.cuda()
  #print(labels)
  #preds = network(images)
  rand_num = []
  for j in range(batch_size):
    rand_num.append(random.randint(0,9)) # creating the rand numbers of batch size
    #print(len(rand_num))
  rand_num = torch.tensor(rand_num)
  rand_num = rand_num.cuda()
  pred1,pred2 =  network(images,rand_num)
  correct_detect, correct_sum = get_num_correct2(pred1, pred2, labels,rand_num)

  total_val_detect_correct += correct_detect
    
  total_val_sum_correct += correct_sum
  

print("val_detect_accuracy :",total_val_detect_correct*100/(len(validation_data)*batch_size),"val_sum_accuracy",total_val_sum_correct*100/(len(validation_data)*batch_size))